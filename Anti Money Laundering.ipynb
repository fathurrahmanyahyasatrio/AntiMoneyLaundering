{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1FDaCYaXLQDOCQv_RIMh8_siYPSWqeHpu",
      "authorship_tag": "ABX9TyPMbnHrLI0XgN7OYQgxlZrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fathurrahmanyahyasatrio/AntiMoneyLaundering/blob/main/Anti%20Money%20Laundering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Business Understanding**"
      ],
      "metadata": {
        "id": "bIsE4EEEcrtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Money laundering is a significant problem involving billions of dollars. Detecting money laundering is challenging because automated algorithms often produce high false positive rates, flagging legitimate transactions as suspicious. Conversely, false negatives, where laundering transactions go undetected, are also a major issue. Criminals make efforts to conceal their illegal activities.\n",
        "\n",
        "Access to actual financial transaction data is highly restricted due to proprietary and privacy concerns. Even when access is possible, accurately labeling each transaction as laundering or legitimate is problematic. The synthetic transaction data provided by IBM addresses these challenges.\n",
        "\n",
        "This data is generated in a virtual world inhabited by individuals, companies, and banks. They engage in various financial interactions, such as purchasing goods and services, placing orders, paying salaries, repaying loans, and more, mostly conducted through banks.\n",
        "\n",
        "A fraction of individuals and companies in this model engage in criminal activities like smuggling, illegal gambling, and extortion. Criminals obtain funds from these activities and attempt to disguise the source of these illicit funds through a series of financial transactions, constituting money laundering. Therefore, this data is labeled and can be used to train and test Anti Money Laundering (AML) models and other applications.\n",
        "\n",
        "The data generator not only models illicit activities but also tracks funds derived from illegal activities through multiple transactions, allowing for labeling of laundering transactions even if they are several steps removed from the illicit source.\n",
        "\n",
        "This IBM generator models the entire money laundering process, including placement (introducing illicit funds), layering (mixing funds in the financial system), and integration (spending illicit funds).\n",
        "\n",
        "Unlike real financial institutions, which only see their own transactions, these synthetic transactions create an entire financial ecosystem. This allows for the development of laundering detection models that understand transactions across institutions but can apply their findings to transactions at a specific bank.\n",
        "\n",
        "IBM has improved this data generator since its initial release, making it more realistic and resolving bugs.\n",
        "\n",
        "Six datasets are provided, divided into two groups based on the level of illicit activity. Each group contains small, medium, and large datasets to accommodate various modeling and computational resources. These datasets are independent, and each can be subdivided chronologically for training, validation, and testing, with a common division being 60% for training, 20% for validation, and 20% for testing."
      ],
      "metadata": {
        "id": "OZLUzDB2cv7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY1ZIEj9dJF0",
        "outputId": "e9d73541-878c-4c31-e0ce-74820ffec101"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yiWL8dbrjYmE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baFfhYRejkCw",
        "outputId": "5b4bf930-84d7-4729-c4b7-48cf2bed3157"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neIcSSMEjt4K",
        "outputId": "56ab0d5d-2618-400b-9eda-f76105a13925"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upezMzGIlKT6",
        "outputId": "c4299e7f-3a98-40a0-eaaf-948dabe15bc4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/pyg_lib-0.3.1%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_cluster-1.6.3%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (887 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.8/887.8 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.3.1+pt21cu118 torch_cluster-1.6.3+pt21cu118 torch_scatter-2.1.2+pt21cu118 torch_sparse-0.6.18+pt21cu118 torch_spline_conv-1.2.2+pt21cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch; print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0InFTkLlgML",
        "outputId": "c73fd434-05fe-4ffe-c751-017048efb56e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import os\n",
        "from typing import Callable, Optional\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "path = '/content/drive/MyDrive/HI-Small_Trans.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "3QQUckD_c_zK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization and Feature Engineering**"
      ],
      "metadata": {
        "id": "0vmIH4BHdfMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV39kRTcdc-h",
        "outputId": "8c0e1fb4-a64f-4ae0-eb67-dc0c1c143f90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
            "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
            "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
            "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
            "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
            "\n",
            "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "0          3697.34          US Dollar      3697.34        US Dollar   \n",
            "1             0.01          US Dollar         0.01        US Dollar   \n",
            "2         14675.57          US Dollar     14675.57        US Dollar   \n",
            "3          2806.97          US Dollar      2806.97        US Dollar   \n",
            "4         36682.97          US Dollar     36682.97        US Dollar   \n",
            "\n",
            "  Payment Format  Is Laundering  \n",
            "0   Reinvestment              0  \n",
            "1         Cheque              0  \n",
            "2   Reinvestment              0  \n",
            "3   Reinvestment              0  \n",
            "4   Reinvestment              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon inspecting the dataframe, we propose the idea of extracting all the accounts involved in transactions, both as receivers and payers. This will enable us to sort and identify potentially suspicious accounts. We can then convert the entire dataset into a node classification problem, where the accounts are treated as nodes and the transactions as edges.\n",
        "\n",
        "To facilitate this, we recommend encoding the object columns into classes using the sklearn LabelEncoder."
      ],
      "metadata": {
        "id": "O458BIovdscC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrbQpme7dtXj",
        "outputId": "a59b3c37-2c98-4f22-b5f8-d3db738c6b7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp              object\n",
            "From Bank               int64\n",
            "Account                object\n",
            "To Bank                 int64\n",
            "Account.1              object\n",
            "Amount Received       float64\n",
            "Receiving Currency     object\n",
            "Amount Paid           float64\n",
            "Payment Currency       object\n",
            "Payment Format         object\n",
            "Is Laundering           int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if theres any null values"
      ],
      "metadata": {
        "id": "4_2mEw_wdwD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jobWecjtd3qY",
        "outputId": "3eac1765-ef59-4304-b6ae-e655f719b807"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp             0\n",
            "From Bank             0\n",
            "Account               0\n",
            "To Bank               0\n",
            "Account.1             0\n",
            "Amount Received       0\n",
            "Receiving Currency    0\n",
            "Amount Paid           0\n",
            "Payment Currency      0\n",
            "Payment Format        0\n",
            "Is Laundering         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 columns representing paid and received amount of each transaction, wondering if there's any necessary to split the amount into two columns, where they have shared the same value, unless there are transaction fee/ transaction between different currency."
      ],
      "metadata": {
        "id": "xxePOZCvZ9ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Amount Received equals to Amount Paid:')\n",
        "print(df['Amount Received'].equals(df['Amount Paid']))\n",
        "print('Receiving Currency equals to Payment Currency:')\n",
        "print(df['Receiving Currency'].equals(df['Payment Currency']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NnlgRjMeQnq",
        "outputId": "d63a6765-f183-4a9f-a0fc-c2468e103154"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount Received equals to Amount Paid:\n",
            "False\n",
            "Receiving Currency equals to Payment Currency:\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result, there seems to be an involvement between different currency."
      ],
      "metadata": {
        "id": "M_RsR44FaRF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "not_equal1 = df.loc[~(df['Amount Received'] == df['Amount Paid'])]\n",
        "not_equal2 = df.loc[~(df['Receiving Currency'] == df['Payment Currency'])]\n",
        "print(not_equal1)\n",
        "print('---------------------------------------------------------------------------')\n",
        "print(not_equal2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxGWB4cbeR1I",
        "outputId": "edf58592-c0fe-432d-9a6f-139c410d78f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "1173     2022/09/01 00:22       1362  80030A870     1362  80030A870   \n",
            "7156     2022/09/01 00:28      11318  800C51010    11318  800C51010   \n",
            "7925     2022/09/01 00:12        795  800D98770      795  800D98770   \n",
            "8467     2022/09/01 00:01       1047  800E92CF0     1047  800E92CF0   \n",
            "11529    2022/09/01 00:22      11157  80135FFC0    11157  80135FFC0   \n",
            "...                   ...        ...        ...      ...        ...   \n",
            "5078167  2022/09/10 23:30      23537  803949A90    23537  803949A90   \n",
            "5078234  2022/09/10 23:59      16163  803638A90    16163  803638A90   \n",
            "5078236  2022/09/10 23:55      16163  803638A90    16163  803638A90   \n",
            "5078316  2022/09/10 23:44     215064  808F06E11   215064  808F06E10   \n",
            "5078318  2022/09/10 23:45     215064  808F06E11   215064  808F06E10   \n",
            "\n",
            "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "1173           52.110000               Euro        61.06        US Dollar   \n",
            "7156           76.060000               Euro        89.12        US Dollar   \n",
            "7925           17.690000  Australian Dollar        12.52        US Dollar   \n",
            "8467           19.430000               Euro        22.77        US Dollar   \n",
            "11529          98.340000               Euro       115.24        US Dollar   \n",
            "...                  ...                ...          ...              ...   \n",
            "5078167     26421.500000             Shekel      7823.96        US Dollar   \n",
            "5078234     47517.490000        Saudi Riyal     12667.62        US Dollar   \n",
            "5078236     11329.850000        Saudi Riyal      3020.41        US Dollar   \n",
            "5078316         0.000006            Bitcoin         0.07        US Dollar   \n",
            "5078318         0.000004            Bitcoin         0.05        US Dollar   \n",
            "\n",
            "        Payment Format  Is Laundering  \n",
            "1173               ACH              0  \n",
            "7156               ACH              0  \n",
            "7925               ACH              0  \n",
            "8467               ACH              0  \n",
            "11529              ACH              0  \n",
            "...                ...            ...  \n",
            "5078167            ACH              0  \n",
            "5078234            ACH              0  \n",
            "5078236            ACH              0  \n",
            "5078316            ACH              0  \n",
            "5078318           Wire              0  \n",
            "\n",
            "[72158 rows x 11 columns]\n",
            "---------------------------------------------------------------------------\n",
            "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
            "1173     2022/09/01 00:22       1362  80030A870     1362  80030A870   \n",
            "7156     2022/09/01 00:28      11318  800C51010    11318  800C51010   \n",
            "7925     2022/09/01 00:12        795  800D98770      795  800D98770   \n",
            "8467     2022/09/01 00:01       1047  800E92CF0     1047  800E92CF0   \n",
            "11529    2022/09/01 00:22      11157  80135FFC0    11157  80135FFC0   \n",
            "...                   ...        ...        ...      ...        ...   \n",
            "5078167  2022/09/10 23:30      23537  803949A90    23537  803949A90   \n",
            "5078234  2022/09/10 23:59      16163  803638A90    16163  803638A90   \n",
            "5078236  2022/09/10 23:55      16163  803638A90    16163  803638A90   \n",
            "5078316  2022/09/10 23:44     215064  808F06E11   215064  808F06E10   \n",
            "5078318  2022/09/10 23:45     215064  808F06E11   215064  808F06E10   \n",
            "\n",
            "         Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
            "1173           52.110000               Euro        61.06        US Dollar   \n",
            "7156           76.060000               Euro        89.12        US Dollar   \n",
            "7925           17.690000  Australian Dollar        12.52        US Dollar   \n",
            "8467           19.430000               Euro        22.77        US Dollar   \n",
            "11529          98.340000               Euro       115.24        US Dollar   \n",
            "...                  ...                ...          ...              ...   \n",
            "5078167     26421.500000             Shekel      7823.96        US Dollar   \n",
            "5078234     47517.490000        Saudi Riyal     12667.62        US Dollar   \n",
            "5078236     11329.850000        Saudi Riyal      3020.41        US Dollar   \n",
            "5078316         0.000006            Bitcoin         0.07        US Dollar   \n",
            "5078318         0.000004            Bitcoin         0.05        US Dollar   \n",
            "\n",
            "        Payment Format  Is Laundering  \n",
            "1173               ACH              0  \n",
            "7156               ACH              0  \n",
            "7925               ACH              0  \n",
            "8467               ACH              0  \n",
            "11529              ACH              0  \n",
            "...                ...            ...  \n",
            "5078167            ACH              0  \n",
            "5078234            ACH              0  \n",
            "5078236            ACH              0  \n",
            "5078316            ACH              0  \n",
            "5078318           Wire              0  \n",
            "\n",
            "[72170 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of both dataframes indicate the presence of transaction fees and transactions involving different currencies. Therefore, we cannot merge or discard the amount columns.\n",
        "\n",
        "Since we intend to encode the columns, it's crucial to ensure that the classes for the same attributes align properly. To do this, let's verify whether the lists of Receiving Currency and Payment Currency are identical."
      ],
      "metadata": {
        "id": "5c193DXEed6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(df['Receiving Currency'].unique()))\n",
        "print(sorted(df['Payment Currency'].unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bexPBqULef9l",
        "outputId": "7b8f069f-91cb-4371-f4fd-d5d78a3c706c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n",
            "['Australian Dollar', 'Bitcoin', 'Brazil Real', 'Canadian Dollar', 'Euro', 'Mexican Peso', 'Ruble', 'Rupee', 'Saudi Riyal', 'Shekel', 'Swiss Franc', 'UK Pound', 'US Dollar', 'Yen', 'Yuan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "SH_obBuQekIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the data preprocessing phase, we carry out the following transformations:\n",
        "\n",
        "1. Normalize the Timestamp using min-max normalization.\n",
        "2. Generate a unique ID for each account by combining the bank code with the account number.\n",
        "3. Create a receiving_df containing information about receiving accounts, received amounts, and currencies.\n",
        "4. Create a paying_df containing information about payer accounts, paid amounts, and currencies.\n",
        "5. Compile a list of currencies utilized in all transactions.\n",
        "6. Apply label encoding using sklearn's LabelEncoder to the 'Payment Format,' 'Payment Currency,' and 'Receiving Currency' columns."
      ],
      "metadata": {
        "id": "PGde-7S6esFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_label_encoder(df, columns):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        for i in columns:\n",
        "            df[i] = le.fit_transform(df[i].astype(str))\n",
        "        return df\n",
        "\n",
        "def preprocess(df):\n",
        "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
        "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
        "\n",
        "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
        "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
        "        df = df.sort_values(by=['Account'])\n",
        "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
        "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
        "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
        "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
        "\n",
        "        return df, receiving_df, paying_df, currency_ls"
      ],
      "metadata": {
        "id": "rJuXrGPDei-u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eql2oNge8au",
        "outputId": "beb51943-d438-4028-e310-ad699961ae40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Timestamp  From Bank          Account  To Bank        Account.1  \\\n",
            "4278714   0.456320      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "2798190   0.285018      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "2798191   0.284233      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "3918769   0.417079      10057  10057_803A115E0    29467  29467_803E020C0   \n",
            "213094    0.000746      10057  10057_803A115E0    10057  10057_803A115E0   \n",
            "\n",
            "         Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
            "4278714        787197.11                  13    787197.11                13   \n",
            "2798190        787197.11                  13    787197.11                13   \n",
            "2798191        681262.19                  13    681262.19                13   \n",
            "3918769        681262.19                  13    681262.19                13   \n",
            "213094         146954.27                  13    146954.27                13   \n",
            "\n",
            "         Payment Format  Is Laundering  \n",
            "4278714               3              0  \n",
            "2798190               3              0  \n",
            "2798191               4              0  \n",
            "3918769               4              0  \n",
            "213094                5              0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(receiving_df.head())\n",
        "print(paying_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NFs3V07fY0R",
        "outputId": "a09b6b92-d0e2-455a-96bf-402b6db15f20"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Account  Amount Received  Receiving Currency\n",
            "4278714  29467_803E020C0        787197.11                  13\n",
            "2798190  29467_803E020C0        787197.11                  13\n",
            "2798191  29467_803E020C0        681262.19                  13\n",
            "3918769  29467_803E020C0        681262.19                  13\n",
            "213094   10057_803A115E0        146954.27                  13\n",
            "                 Account  Amount Paid  Payment Currency\n",
            "4278714  10057_803A115E0    787197.11                13\n",
            "2798190  10057_803A115E0    787197.11                13\n",
            "2798191  10057_803A115E0    681262.19                13\n",
            "3918769  10057_803A115E0    681262.19                13\n",
            "213094   10057_803A115E0    146954.27                13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(currency_ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeFpDCEEfh-4",
        "outputId": "5b687909-bf51-46ff-98a4-cf2a189a6547"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Our goal is to extract all the unique accounts from both payers and receivers to serve as nodes in our graph. This information comprises the unique account ID, bank code, and the 'Is Laundering' label.\n",
        "\n",
        "In this context, we identify both payers and receivers involved in illicit transactions as suspicious accounts, and we assign a 'Is Laundering' label value of 1 to both of these accounts."
      ],
      "metadata": {
        "id": "L1lfrmJufoXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_account(df):\n",
        "        ldf = df[['Account', 'From Bank']]\n",
        "        rdf = df[['Account.1', 'To Bank']]\n",
        "        suspicious = df[df['Is Laundering']==1]\n",
        "        s1 = suspicious[['Account', 'Is Laundering']]\n",
        "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
        "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
        "        suspicious = pd.concat([s1, s2], join='outer')\n",
        "        suspicious = suspicious.drop_duplicates()\n",
        "\n",
        "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
        "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
        "        df = pd.concat([ldf, rdf], join='outer')\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        df['Is Laundering'] = 0\n",
        "        df.set_index('Account', inplace=True)\n",
        "        df.update(suspicious.set_index('Account'))\n",
        "        df = df.reset_index()\n",
        "        return df"
      ],
      "metadata": {
        "id": "Yi4nzkxufpFY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look on the account' list"
      ],
      "metadata": {
        "id": "KvJkm7isbNsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accounts = get_all_account(df)\n",
        "print(accounts.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBEKktFZfuez",
        "outputId": "99dc3a24-1f39-45c0-a414-c3cbf899c0e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Account   Bank  Is Laundering\n",
            "0  10057_803A115E0  10057            0.0\n",
            "1  10057_803AA8E90  10057            0.0\n",
            "2  10057_803AAB430  10057            0.0\n",
            "3  10057_803AACE20  10057            0.0\n",
            "4  10057_803AB4F70  10057            0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Node Features**"
      ],
      "metadata": {
        "id": "oMR3kXyugK8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node."
      ],
      "metadata": {
        "id": "Z6RCsdzQgNmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
        "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
        "        return accounts\n",
        "\n",
        "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
        "    for i in currency_ls:\n",
        "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
        "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
        "    accounts = accounts.fillna(0)\n",
        "    return accounts"
      ],
      "metadata": {
        "id": "AEtud6YvgFes"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can establish the node attributes based on the bank code and the average of the amounts that have been paid and received in various currency types."
      ],
      "metadata": {
        "id": "0zIiqF-1gShD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_node_attr(currency_ls, paying_df,receiving_df, accounts):\n",
        "        node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
        "        node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
        "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
        "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
        "        node_df = df_label_encoder(node_df,['Bank'])\n",
        "#         node_df = torch.from_numpy(node_df.values).to(torch.float)  # comment for visualization\n",
        "        return node_df, node_label"
      ],
      "metadata": {
        "id": "J56Xddm6gTaw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
        "print(node_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPpGfiDVgXcB",
        "outputId": "2587533d-98ce-459d-c103-50dd1f7eb5fb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
            "0     2         0.0         0.0         0.0         0.0         0.0   \n",
            "1     2         0.0         0.0         0.0         0.0         0.0   \n",
            "2     2         0.0         0.0         0.0         0.0         0.0   \n",
            "3     2         0.0         0.0         0.0         0.0         0.0   \n",
            "4     2         0.0         0.0         0.0         0.0         0.0   \n",
            "\n",
            "   avg paid 5  avg paid 6  avg paid 7  avg paid 8  avg paid 9  avg paid 10  \\\n",
            "0         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "1         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "2         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "3         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "4         0.0         0.0         0.0         0.0         0.0          0.0   \n",
            "\n",
            "   avg paid 11   avg paid 12  avg paid 13  avg paid 14  avg received 0  \\\n",
            "0          0.0   1922.000000          0.0          0.0             0.0   \n",
            "1          0.0    480.223333          0.0          0.0             0.0   \n",
            "2          0.0  14675.570000          0.0          0.0             0.0   \n",
            "3          0.0  37340.843333          0.0          0.0             0.0   \n",
            "4          0.0  49649.409677          0.0          0.0             0.0   \n",
            "\n",
            "   avg received 1  avg received 2  avg received 3  avg received 4  \\\n",
            "0             0.0             0.0             0.0             0.0   \n",
            "1             0.0             0.0             0.0             0.0   \n",
            "2             0.0             0.0             0.0             0.0   \n",
            "3             0.0             0.0             0.0             0.0   \n",
            "4             0.0             0.0             0.0             0.0   \n",
            "\n",
            "   avg received 5  avg received 6  avg received 7  avg received 8  \\\n",
            "0             0.0             0.0             0.0             0.0   \n",
            "1             0.0             0.0             0.0             0.0   \n",
            "2             0.0             0.0             0.0             0.0   \n",
            "3             0.0             0.0             0.0             0.0   \n",
            "4             0.0             0.0             0.0             0.0   \n",
            "\n",
            "   avg received 9  avg received 10  avg received 11  avg received 12  \\\n",
            "0             0.0              0.0              0.0       330.166429   \n",
            "1             0.0              0.0              0.0       119.992000   \n",
            "2             0.0              0.0              0.0     14675.570000   \n",
            "3             0.0              0.0              0.0       756.486190   \n",
            "4             0.0              0.0              0.0      3120.573333   \n",
            "\n",
            "   avg received 13  avg received 14  \n",
            "0              0.0              0.0  \n",
            "1              0.0              0.0  \n",
            "2              0.0              0.0  \n",
            "3              0.0              0.0  \n",
            "4              0.0              0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edge Features**"
      ],
      "metadata": {
        "id": "EvqxZgfShjM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it cmes to edge characteristics, we want to treat each transaction as an edge.\n",
        "Regarding the edge index, we'll have to replace all the accounts with indices and compile them into a list with a size of [2, number of transactions]\n",
        "For edge attributes, we will include 'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'"
      ],
      "metadata": {
        "id": "ejY0XSZHhwwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_edge_df(accounts, df):\n",
        "        accounts = accounts.reset_index(drop=True)\n",
        "        accounts['ID'] = accounts.index\n",
        "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
        "        df['From'] = df['Account'].map(mapping_dict)\n",
        "        df['To'] = df['Account.1'].map(mapping_dict)\n",
        "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
        "\n",
        "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
        "\n",
        "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
        "\n",
        "#         edge_attr = torch.from_numpy(df.values).to(torch.float)  # comment for visualization\n",
        "\n",
        "        edge_attr = df  # for visualization\n",
        "        return edge_attr, edge_index"
      ],
      "metadata": {
        "id": "Asun-23phkrv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_attr, edge_index = get_edge_df(accounts, df)\n",
        "print(edge_attr.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrVlGJJ9h00H",
        "outputId": "22e30a93-5498-4c29-ec4e-cd529befd63f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
            "4278714   0.456320        787197.11                  13    787197.11   \n",
            "2798190   0.285018        787197.11                  13    787197.11   \n",
            "2798191   0.284233        681262.19                  13    681262.19   \n",
            "3918769   0.417079        681262.19                  13    681262.19   \n",
            "213094    0.000746        146954.27                  13    146954.27   \n",
            "\n",
            "         Payment Currency  Payment Format  \n",
            "4278714                13               3  \n",
            "2798190                13               3  \n",
            "2798191                13               4  \n",
            "3918769                13               4  \n",
            "213094                 13               5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VonnsoQliLq3",
        "outputId": "e49c846e-00fc-40e7-d17b-24218bd68455"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[     0,      0,      0,  ..., 496997, 496997, 496998],\n",
            "        [299458, 299458, 299458,  ..., 496997, 496997, 496998]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Architecture**"
      ],
      "metadata": {
        "id": "yP0GbaXKixxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will employ Graph Attention Networks as the foundational model for the work. This model consists of two GATConv layers, followed by a linear layer that produces a sigmoid output for the classification"
      ],
      "metadata": {
        "id": "addiTiWrcT0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GATConv, Linear\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, int(hidden_channels/4), heads=1, concat=False, dropout=0.6)\n",
        "        self.lin = Linear(int(hidden_channels/4), out_channels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = self.lin(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "U1dZ-Uo1izdW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build dataset using the functions above"
      ],
      "metadata": {
        "id": "OU39Cpexc7Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AMLtoGraph(InMemoryDataset):\n",
        "\n",
        "    def __init__(self, root: str, edge_window_size: int = 10,\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 pre_transform: Optional[Callable] = None):\n",
        "        self.edge_window_size = edge_window_size\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self) -> str:\n",
        "        return 'HI-Small_Trans.csv'\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> str:\n",
        "        return 'data.pt'\n",
        "\n",
        "    @property\n",
        "    def num_nodes(self) -> int:\n",
        "        return self._data.edge_index.max().item() + 1\n",
        "\n",
        "    def df_label_encoder(self, df, columns):\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        for i in columns:\n",
        "            df[i] = le.fit_transform(df[i].astype(str))\n",
        "        return df\n",
        "\n",
        "\n",
        "    def preprocess(self, df):\n",
        "        df = self.df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
        "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
        "\n",
        "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
        "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
        "        df = df.sort_values(by=['Account'])\n",
        "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
        "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
        "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
        "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
        "\n",
        "        return df, receiving_df, paying_df, currency_ls\n",
        "\n",
        "    def get_all_account(self, df):\n",
        "        ldf = df[['Account', 'From Bank']]\n",
        "        rdf = df[['Account.1', 'To Bank']]\n",
        "        suspicious = df[df['Is Laundering']==1]\n",
        "        s1 = suspicious[['Account', 'Is Laundering']]\n",
        "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
        "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
        "        suspicious = pd.concat([s1, s2], join='outer')\n",
        "        suspicious = suspicious.drop_duplicates()\n",
        "\n",
        "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
        "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
        "        df = pd.concat([ldf, rdf], join='outer')\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        df['Is Laundering'] = 0\n",
        "        df.set_index('Account', inplace=True)\n",
        "        df.update(suspicious.set_index('Account'))\n",
        "        df = df.reset_index()\n",
        "        return df\n",
        "\n",
        "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
        "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
        "        return accounts\n",
        "\n",
        "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
        "        for i in currency_ls:\n",
        "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
        "            accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
        "        accounts = accounts.fillna(0)\n",
        "        return accounts\n",
        "\n",
        "    def get_edge_df(self, accounts, df):\n",
        "        accounts = accounts.reset_index(drop=True)\n",
        "        accounts['ID'] = accounts.index\n",
        "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
        "        df['From'] = df['Account'].map(mapping_dict)\n",
        "        df['To'] = df['Account.1'].map(mapping_dict)\n",
        "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
        "\n",
        "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
        "\n",
        "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
        "\n",
        "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
        "        return edge_attr, edge_index\n",
        "\n",
        "    def get_node_attr(self, currency_ls, paying_df,receiving_df, accounts):\n",
        "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
        "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
        "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
        "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
        "        node_df = self.df_label_encoder(node_df,['Bank'])\n",
        "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
        "        return node_df, node_label\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
        "        accounts = self.get_all_account(df)\n",
        "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
        "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
        "\n",
        "        data = Data(x=node_attr,\n",
        "                    edge_index=edge_index,\n",
        "                    y=node_label,\n",
        "                    edge_attr=edge_attr\n",
        "                    )\n",
        "\n",
        "        data_list = [data]\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ],
      "metadata": {
        "id": "qdvImqU-i7Lz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "nTDXM5woi87m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dataset = AMLtoGraph('/content/drive/MyDrive/AntiMoneyLaundering')\n",
        "data = dataset[0]\n",
        "epoch = 100\n",
        "\n",
        "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
        "data = split(data)\n",
        "\n",
        "train_loader = loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[30] * 2,\n",
        "    batch_size=256,\n",
        "    input_nodes=data.train_mask,\n",
        ")\n",
        "\n",
        "test_loader = loader = NeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=[30] * 2,\n",
        "    batch_size=256,\n",
        "    input_nodes=data.val_mask,\n",
        ")\n",
        "\n",
        "for i in range(epoch):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data.to(device)\n",
        "        pred = model(data.x, data.edge_index, data.edge_attr)\n",
        "        ground_truth = data.y\n",
        "        loss = criterion(pred, ground_truth.unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss)\n",
        "    if epoch%10 == 0:\n",
        "        print(f\"Epoch: {i:03d}, Loss: {total_loss:.4f}\")\n",
        "        model.eval()\n",
        "        acc = 0\n",
        "        total = 0\n",
        "        for test_data in test_loader:\n",
        "            test_data.to(device)\n",
        "            pred = model(test_data.x, test_data.edge_index, test_data.edge_attr)\n",
        "            ground_truth = test_data.y\n",
        "            correct = (pred == ground_truth.unsqueeze(1)).sum().item()\n",
        "            total += len(ground_truth)\n",
        "            acc += correct\n",
        "        acc = acc/total\n",
        "        print('accuracy:', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olXODAWFi-G4",
        "outputId": "a5555987-f577-42b9-b9ad-d6d4b5da3a9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 6008.9402\n",
            "accuracy: 0.9234248659034505\n",
            "Epoch: 001, Loss: 2416.2613\n",
            "accuracy: 0.9298559080694484\n",
            "Epoch: 002, Loss: 1825.3569\n",
            "accuracy: 0.9303681534272902\n",
            "Epoch: 003, Loss: 1826.4374\n",
            "accuracy: 0.9335804076726599\n",
            "Epoch: 004, Loss: 1786.2608\n",
            "accuracy: 0.9401137068844714\n",
            "Epoch: 005, Loss: 1735.3178\n",
            "accuracy: 0.9433595900351313\n",
            "Epoch: 006, Loss: 1722.6374\n",
            "accuracy: 0.9462822321616186\n",
            "Epoch: 007, Loss: 1706.3515\n",
            "accuracy: 0.9479942126790389\n",
            "Epoch: 008, Loss: 1678.3283\n",
            "accuracy: 0.9502129299257873\n",
            "Epoch: 009, Loss: 1653.5942\n",
            "accuracy: 0.9519212473837588\n",
            "Epoch: 010, Loss: 1614.1431\n",
            "accuracy: 0.9590698279441857\n",
            "Epoch: 011, Loss: 1605.9702\n",
            "accuracy: 0.9592291327743712\n",
            "Epoch: 012, Loss: 1577.1260\n",
            "accuracy: 0.9592315816344407\n",
            "Epoch: 013, Loss: 1581.4886\n",
            "accuracy: 0.9640655028827675\n",
            "Epoch: 014, Loss: 1576.8501\n",
            "accuracy: 0.964171759504686\n",
            "Epoch: 015, Loss: 1550.5925\n",
            "accuracy: 0.9644488977955912\n",
            "Epoch: 016, Loss: 1534.5545\n",
            "accuracy: 0.9649216755918122\n",
            "Epoch: 017, Loss: 1531.9577\n",
            "accuracy: 0.9652181312190923\n",
            "Epoch: 018, Loss: 1530.2275\n",
            "accuracy: 0.9654052322584197\n",
            "Epoch: 019, Loss: 1512.5838\n",
            "accuracy: 0.9657291562406165\n",
            "Epoch: 020, Loss: 1484.5479\n",
            "accuracy: 0.9660734399639559\n",
            "Epoch: 021, Loss: 1484.6861\n",
            "accuracy: 0.9662111788811112\n",
            "Epoch: 022, Loss: 1469.5861\n",
            "accuracy: 0.966537373939591\n",
            "Epoch: 023, Loss: 1467.2482\n",
            "accuracy: 0.9666488300335562\n",
            "Epoch: 024, Loss: 1477.1312\n",
            "accuracy: 0.9668297225713098\n",
            "Epoch: 025, Loss: 1454.6557\n",
            "accuracy: 0.9669848388533788\n",
            "Epoch: 026, Loss: 1454.4961\n",
            "accuracy: 0.9668515200352356\n",
            "Epoch: 027, Loss: 1450.7369\n",
            "accuracy: 0.9670331320777388\n",
            "Epoch: 028, Loss: 1429.8254\n",
            "accuracy: 0.9672889004642963\n",
            "Epoch: 029, Loss: 1414.4112\n",
            "accuracy: 0.9676702677548324\n",
            "Epoch: 030, Loss: 1417.9865\n",
            "accuracy: 0.9676654494522535\n",
            "Epoch: 031, Loss: 1424.3048\n",
            "accuracy: 0.9678861422321008\n",
            "Epoch: 032, Loss: 1408.6193\n",
            "accuracy: 0.9679846606724473\n",
            "Epoch: 033, Loss: 1396.8124\n",
            "accuracy: 0.9679827480098668\n",
            "Epoch: 034, Loss: 1396.7225\n",
            "accuracy: 0.9680265436238252\n",
            "Epoch: 035, Loss: 1414.9011\n",
            "accuracy: 0.967997918563809\n",
            "Epoch: 036, Loss: 1394.1081\n",
            "accuracy: 0.9681511133350013\n",
            "Epoch: 037, Loss: 1381.6157\n",
            "accuracy: 0.9683862566362816\n",
            "Epoch: 038, Loss: 1371.2813\n",
            "accuracy: 0.9685235235235236\n",
            "Epoch: 039, Loss: 1375.9402\n",
            "accuracy: 0.9686914717812609\n",
            "Epoch: 040, Loss: 1369.8208\n",
            "accuracy: 0.9687326466188735\n",
            "Epoch: 041, Loss: 1364.4139\n",
            "accuracy: 0.9687876711300963\n",
            "Epoch: 042, Loss: 1384.6377\n",
            "accuracy: 0.9687961290387146\n",
            "Epoch: 043, Loss: 1375.3459\n",
            "accuracy: 0.9689368878835346\n",
            "Epoch: 044, Loss: 1357.1740\n",
            "accuracy: 0.9691742237222275\n",
            "Epoch: 045, Loss: 1336.6596\n",
            "accuracy: 0.9693889297637102\n",
            "Epoch: 046, Loss: 1349.9994\n",
            "accuracy: 0.9693725810247192\n",
            "Epoch: 047, Loss: 1336.3899\n",
            "accuracy: 0.9696058065323488\n",
            "Epoch: 048, Loss: 1327.0462\n",
            "accuracy: 0.9698530222119807\n",
            "Epoch: 049, Loss: 1333.5432\n",
            "accuracy: 0.9698956154485133\n",
            "Epoch: 050, Loss: 1315.2291\n",
            "accuracy: 0.9698967875564717\n",
            "Epoch: 051, Loss: 1327.6903\n",
            "accuracy: 0.9700790317979109\n",
            "Epoch: 052, Loss: 1317.9629\n",
            "accuracy: 0.9703128362451643\n",
            "Epoch: 053, Loss: 1329.9427\n",
            "accuracy: 0.9703441579242412\n",
            "Epoch: 054, Loss: 1295.7529\n",
            "accuracy: 0.9705757207146325\n",
            "Epoch: 055, Loss: 1318.0075\n",
            "accuracy: 0.9704229369873434\n",
            "Epoch: 056, Loss: 1311.1879\n",
            "accuracy: 0.9705106713038256\n",
            "Epoch: 057, Loss: 1312.2009\n",
            "accuracy: 0.9705221209253891\n",
            "Epoch: 058, Loss: 1300.4750\n",
            "accuracy: 0.9706494754544727\n",
            "Epoch: 059, Loss: 1297.7418\n",
            "accuracy: 0.9708103347328493\n",
            "Epoch: 060, Loss: 1284.0233\n",
            "accuracy: 0.9707096638592383\n",
            "Epoch: 061, Loss: 1298.0350\n",
            "accuracy: 0.9709385278524548\n",
            "Epoch: 062, Loss: 1278.8552\n",
            "accuracy: 0.9708444302048499\n",
            "Epoch: 063, Loss: 1285.5080\n",
            "accuracy: 0.9707934285214174\n",
            "Epoch: 064, Loss: 1297.5678\n",
            "accuracy: 0.9709572014031015\n",
            "Epoch: 065, Loss: 1294.5502\n",
            "accuracy: 0.9709476677530627\n",
            "Epoch: 066, Loss: 1280.7791\n",
            "accuracy: 0.9708315193730953\n",
            "Epoch: 067, Loss: 1265.9996\n",
            "accuracy: 0.9709606702769797\n",
            "Epoch: 068, Loss: 1266.6024\n",
            "accuracy: 0.9710808145036525\n",
            "Epoch: 069, Loss: 1266.9808\n",
            "accuracy: 0.9709637396942288\n",
            "Epoch: 070, Loss: 1277.7741\n",
            "accuracy: 0.970994910597667\n",
            "Epoch: 071, Loss: 1272.5347\n",
            "accuracy: 0.9714891977239402\n",
            "Epoch: 072, Loss: 1261.7986\n",
            "accuracy: 0.9717555990606896\n",
            "Epoch: 073, Loss: 1260.5572\n",
            "accuracy: 0.9716309571485783\n",
            "Epoch: 074, Loss: 1265.7862\n",
            "accuracy: 0.9718223859382195\n",
            "Epoch: 075, Loss: 1257.9814\n",
            "accuracy: 0.9716261970589414\n",
            "Epoch: 076, Loss: 1273.1063\n",
            "accuracy: 0.9715249250721759\n",
            "Epoch: 077, Loss: 1242.8638\n",
            "accuracy: 0.9717621612961368\n",
            "Epoch: 078, Loss: 1259.1801\n",
            "accuracy: 0.9718924546055134\n",
            "Epoch: 079, Loss: 1256.7516\n",
            "accuracy: 0.9718179452274183\n",
            "Epoch: 080, Loss: 1249.2762\n",
            "accuracy: 0.9720052865553286\n",
            "Epoch: 081, Loss: 1251.1099\n",
            "accuracy: 0.9719898326795292\n",
            "Epoch: 082, Loss: 1249.1415\n",
            "accuracy: 0.9719210147247119\n",
            "Epoch: 083, Loss: 1260.7836\n",
            "accuracy: 0.9721911955481871\n",
            "Epoch: 084, Loss: 1245.0801\n",
            "accuracy: 0.9719565837474291\n",
            "Epoch: 085, Loss: 1250.6273\n",
            "accuracy: 0.9719774938929158\n",
            "Epoch: 086, Loss: 1242.6050\n",
            "accuracy: 0.9718813982709338\n",
            "Epoch: 087, Loss: 1248.1372\n",
            "accuracy: 0.9720031841872062\n",
            "Epoch: 088, Loss: 1234.9758\n",
            "accuracy: 0.9721320089073485\n",
            "Epoch: 089, Loss: 1237.0339\n",
            "accuracy: 0.9718118857463119\n",
            "Epoch: 090, Loss: 1261.4776\n",
            "accuracy: 0.9720424294302863\n",
            "Epoch: 091, Loss: 1240.8253\n",
            "accuracy: 0.9723591064862296\n",
            "Epoch: 092, Loss: 1242.3255\n",
            "accuracy: 0.9723465393125682\n",
            "Epoch: 093, Loss: 1245.2392\n",
            "accuracy: 0.9725026401269263\n",
            "Epoch: 094, Loss: 1234.9536\n",
            "accuracy: 0.9725858038811334\n",
            "Epoch: 095, Loss: 1230.4035\n",
            "accuracy: 0.97239850256246\n",
            "Epoch: 096, Loss: 1235.1196\n",
            "accuracy: 0.9724387778589514\n",
            "Epoch: 097, Loss: 1227.5989\n",
            "accuracy: 0.9724308394334062\n",
            "Epoch: 098, Loss: 1210.7971\n",
            "accuracy: 0.9724499294357866\n",
            "Epoch: 099, Loss: 1227.7144\n",
            "accuracy: 0.9724555811847352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, we have used Graph Neural Networks (GNN), where it's a class of methods that overcome the drawback by applying the machine learning task directly on the network data through a neural network. GNN were able to solve various tasks as well as unsupervised embedding. This is crucial for Anti Money Laundering (AML) Application where new transactions appear continuously.\n",
        "\n",
        "Customers labeled as \"regular\" may involved in a suspicious activity in the form of money laundering, which haven't been controlled in the current AML system. Implementing a predictive model approach for suspicious transactions with real AML system where key decisions need to be made. In order to increase the performance of the money laundering approach along with the dataset is rich in terms of number, that cntains network data from financial transactions.\n",
        "\n",
        "This is the first attempt to leverage Graph ne within AML which showcased promising results. Ultimately, it leads to the contribution that will aid in te continuous combat of money laundering."
      ],
      "metadata": {
        "id": "9g9S99vYnyqx"
      }
    }
  ]
}